{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"start\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> CISC 665_Workshop 01_JohnyMandal</h1>\n",
    "<h4> Facial Recognition: Edge Detection and Image Filtering</h4></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Quick Links:\n",
    "<a href = \"#convol\"> What 2D convolution is, and how to use it</a>\n",
    "\n",
    "<a href = \"#blur\"> How to blur an image </a>  \n",
    "\n",
    "<a href = \"#edge\"> How to detect edges in an image </a>  \n",
    "    \n",
    "<a href = \"#motion\"> How to apply motion blur to an image </a>  \n",
    "    \n",
    "<a href = \"#sharpen\"> How to sharpen an image </a> \n",
    "\n",
    "<a href = \"#emboss\"> How to emboss an image </a>  \n",
    "    \n",
    "<a href = \"#dilate\"> How to erode and dilate an image </a>  \n",
    "    \n",
    "<a href = \"#vignette\"> How to create a vignette filter </a>  \n",
    "    \n",
    "<a href = \"#contrast\"> How to enhance image contrast </a>  \n",
    "\n",
    "<a href = \"#end\"> JUMP TO END</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"convol\" />  \n",
    "## What 2D convolution is, and how to use it\n",
    "\n",
    "<a href = \"#start\"> JUMP TO START</a> \n",
    "\n",
    "#### Concolution is a basic image processing operation in which using mathematical operators we change the image values (whole image or a subset of an image) in order to apply some effects.\n",
    "\n",
    "#### Below are some of the popular convolution methods using OpenCV:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from  matplotlib  import  pyplot  as  plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv.imread('images/peacock-feathers.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"blur\" />  \n",
    "## How to blur an image\n",
    "\n",
    "<a href = \"#start\"> JUMP TO START</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv.imread('images/peacock-feathers.jpg')\n",
    "\n",
    "rows, cols = img.shape[:2]\n",
    "\n",
    "#identity\n",
    "kernel_identity = np.array([[0,0,0],[0,1,0],[0,0,0]])\n",
    "output=cv2.filter2D(img,-1,kernel_identity)\n",
    "plt.title(\"Identity filter\")\n",
    "plt.imshow(output)\n",
    "plt.show()\n",
    "# cv2.imshow('Identity filter',output)\n",
    "\n",
    "#blur\n",
    "kernel_3x3 = np.ones((3,3),np.float32) / 9.0\n",
    "output=cv2.filter2D(img,-1,kernel_3x3) \n",
    "plt.title(\"3 X 3 filter\")\n",
    "plt.imshow(output)\n",
    "plt.show()\n",
    "# cv2.imshow('Identity filter',output)\n",
    "\n",
    "#larger blur\n",
    "kernel_5x5 = np.ones((5,5),np.float32) / 25.0\n",
    "output=cv2.filter2D(img,-1,kernel_5x5)\n",
    "plt.title(\"5 X 5 filter\")\n",
    "plt.imshow(output)\n",
    "plt.show()\n",
    "# cv2.imshow('Identity filter',output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"motion\" />  \n",
    "## How to apply motion blur to an image\n",
    "\n",
    "<a href = \"#start\"> JUMP TO START</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#motion blur\n",
    "size=15\n",
    "kernel_motion_blur = np.zeros((size,size))\n",
    "kernel_motion_blur[int((size-1)/2),:] = np.ones(size)\n",
    "kernel_motion_blur = kernel_motion_blur /  size\n",
    "output=cv2.filter2D(img,-1,kernel_motion_blur)\n",
    "plt.title(\"Motion Blur\")\n",
    "plt.imshow(output); plt.show()\n",
    "# cv2.imshow('Motion blur',output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"edge\" />  \n",
    "## How to detect edges in an image\n",
    "\n",
    "<a href = \"#start\"> JUMP TO START</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imwrite('images/peacock-feathers_gray.jpg', cv_gray)\n",
    "gray=cv2.imread('images/peacock-feathers_gray.jpg')\n",
    "# plt.imshow(gray); plt.show()\n",
    "#Sobel-Horizontal\n",
    "sobel_horizontal = cv2.Sobel(gray,cv2.CV_64F, 1,0,ksize=5)\n",
    "plt.title(\"Sobel-Horizontal\")\n",
    "plt.imshow(sobel_horizontal); plt.show()\n",
    "# cv2.imshow('Sobel horizontal',sobel_horizontal)\n",
    "\n",
    "#Sobel-Vertical\n",
    "sobel_vertical = cv2.Sobel(gray,cv2.CV_64F, 1,0,ksize=5)\n",
    "plt.title(\"Sobel-Vertical\")\n",
    "plt.imshow(sobel_vertical); plt.show()\n",
    "# cv2.imshow('Sobel vertical',sobel_vertical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"sharpen\" />  \n",
    "## How to sharpen an image\n",
    "\n",
    "<a href = \"#start\"> JUMP TO START</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sharpen\n",
    "kernel_sharpen_1 = np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]])\n",
    "output1=cv2.filter2D(img,-1,kernel_sharpen_1)\n",
    "plt.title(\"Sharpening\")\n",
    "plt.imshow(output1); plt.show()\n",
    "#cv2.imshow('Sharpening',output1)\n",
    "\n",
    "#more shapening\n",
    "kernel_sharpen_2 = np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]])\n",
    "output2=cv2.filter2D(img,-1,kernel_sharpen_2)\n",
    "plt.title(\"Excessive shapening\")\n",
    "plt.imshow(output2); plt.show()\n",
    "#cv2.imshow('Excessive sharpening',output2)\n",
    "\n",
    "#edge enhancement\n",
    "kernel_sharpen_3 = np.array([[-1,-1,-1,-1,-1],[-1,2,2,2,-1],[-1,2,8,2,-1],[-1,2,2,2,-1],[-1,-1,-1,-1,-1]])/8.0\n",
    "output3=cv2.filter2D(img,-1,kernel_sharpen_3)\n",
    "plt.title(\"Edge enhancement\")\n",
    "plt.imshow(output3); plt.show()\n",
    "#cv2.imshow('Edge Enhancement',output3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"emboss\" />  \n",
    "## How to emboss an image\n",
    "\n",
    "<a href = \"#start\"> JUMP TO START</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imwrite('images/peacock-feathers_gray.jpg', cv_gray)\n",
    "gray=cv2.imread('images/peacock-feathers_gray.jpg')\n",
    "plt.imshow(gray); plt.show()\n",
    "#emboss\n",
    "kernel_emboss1=np.array([[0,-1,1],[1,0,-1],[1,1,0]])\n",
    "output=cv2.filter2D(gray,-1,kernel_emboss1)+128\n",
    "plt.title(\"Emboss1\")\n",
    "plt.imshow(output); plt.show()\n",
    "#cv2.imshow('Emboss1',output)\n",
    "\n",
    "#emboss2\n",
    "kernel_emboss2=np.array([[-1,-1,0],[-1,0,11],[0,1,1]])\n",
    "output=cv2.filter2D(gray,-1,kernel_emboss2)+128\n",
    "plt.title(\"Emboss2\")\n",
    "plt.imshow(output); plt.show()\n",
    "#cv2.imshow('Emboss2',output)\n",
    "\n",
    "#emboss3\n",
    "kernel_emboss3=np.array([[1,0,0],[0,0,0],[0,0,-1]])\n",
    "output=cv2.filter2D(gray,-1,kernel_emboss3)+128\n",
    "plt.title(\"Emboss3\")\n",
    "plt.imshow(output); plt.show()\n",
    "#cv2.imshow('Emboss3',output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"dilate\" />  \n",
    "## How to erode and dilate an image\n",
    "\n",
    "<a href = \"#start\"> JUMP TO START</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#erode\n",
    "kernel_erode=np.ones((5,5),np.uint8)\n",
    "img_erosion = cv2.erode(img,kernel_erode,iterations = 1)\n",
    "plt.title(\"Erode\")\n",
    "plt.imshow(img_erosion); plt.show()\n",
    "#cv2.imshow('Erode',img_erosion)\n",
    "\n",
    "#dilate\n",
    "img_dilatation = cv2.dilate(img,kernel_erode,iterations = 1)\n",
    "plt.title(\"Dilate\")\n",
    "plt.imshow(img_dilatation); plt.show()\n",
    "#cv2.imshow('Dilate',img_dilatation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"vignette\" />  \n",
    "## How to create a vignette filter\n",
    "\n",
    "<a href = \"#start\"> JUMP TO START</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vignette\n",
    "kernel_gauss_x= cv2.getGaussianKernel(cols,200)\n",
    "kernel_gauss_y = cv2.getGaussianKernel(rows,200)\n",
    "kernel = kernel_gauss_y * kernel_gauss_x.T\n",
    "mask=255*kernel/np.linalg.norm(kernel)\n",
    "output=np.copy(img)\n",
    "for i in range(3):\n",
    "  output[:,:,i]=output[:,:,i] * mask\n",
    "plt.title(\"Vignette\")\n",
    "plt.imshow(output); plt.show()\n",
    "#cv2.imshow('Vignette',output)\n",
    "\n",
    "#shifted vignette\n",
    "kernel_gauss_x= cv2.getGaussianKernel(int(1.5*cols),200)\n",
    "kernel_gauss_y = cv2.getGaussianKernel(int(1.5*rows),200)\n",
    "kernel = kernel_gauss_y * kernel_gauss_x.T\n",
    "mask=255*kernel/np.linalg.norm(kernel)\n",
    "mask = mask[int(0.5*rows):,int(0.5*cols):]\n",
    "output=np.copy(img)\n",
    "for i in range(3):\n",
    "  output[:,:,i]=output[:,:,i] * mask\n",
    "plt.title(\"Shifted Vignette\")\n",
    "plt.imshow(output); plt.show()\n",
    "#cv2.imshow('Shifted Vignette',output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"contrast\" />  \n",
    "## How to enhance image contrast\n",
    "\n",
    "<a href = \"#start\"> JUMP TO START</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image=cv2.imread('images/puppy_gray.jpg')\n",
    "plt.title(\"Original image\")\n",
    "plt.imshow(gray_image); plt.show()\n",
    "\n",
    "cv_gray = cv2.cvtColor(gray_image, cv2.COLOR_BGR2GRAY) ## For some reason CV needs an explicit B&W conversion\n",
    "#constrast: b&w\n",
    "histeq=cv2.equalizeHist(cv_gray)\n",
    "# cv2.imshow('Input',img)\n",
    "plt.title(\"Histogram equalized-B&W\")\n",
    "plt.imshow(histeq); plt.show()\n",
    "#cv2.imshow('Historgram equalized',histeq)\n",
    "\n",
    "#contrast:RGB\n",
    "img_yuv=cv2.cvtColor(img,cv2.COLOR_BGR2YUV)\n",
    "img_yuv[:,:,0]=cv2.equalizeHist(img_yuv[:,:,0])\n",
    "output=cv2.cvtColor(img_yuv,cv2.COLOR_YUV2BGR)\n",
    "plt.title(\"Histogram equalized-RGB (Colored image)\")\n",
    "plt.imshow(output); plt.show()\n",
    "#cv2.imshow('Histogram equalized',img)\n",
    "\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Thank you!!! </h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"end\" />\n",
    "<a href = \"#start\"> JUMP TO START </a> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
